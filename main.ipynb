{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Created by Weiyu\n",
    "\n",
    "from aip import AipOcr\n",
    "from screenshot import get_screenshot\n",
    "import os\n",
    "import re\n",
    "from zhon.hanzi import punctuation\n",
    "import string\n",
    "import time\n",
    "import urllib.parse\n",
    "import requests\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import random\n",
    "import json\n",
    "from fake_useragent import UserAgent\n",
    "import traceback\n",
    "from config import Config\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header():\n",
    "    location = os.getcwd() + '/fake_useragent.json'\n",
    "    ua = UserAgent(path=location)\n",
    "    return ua.random\n",
    "\n",
    "\n",
    "class QA(object):\n",
    "    def __init__(self, config, history=False):\n",
    "        self.client = AipOcr(\n",
    "            config.OCR_APP_ID, config.OCR_API_KEY, config.OCR_SECRET_KEY)\n",
    "        self.options = config.OCR_OPTIONS\n",
    "        self.config = config\n",
    "        if not history:\n",
    "            os.system(\"adb devices\")\n",
    "            try:\n",
    "                headers = {'User-Agent': get_header()}\n",
    "            except Exception as e:\n",
    "                print(traceback.format_exc())\n",
    "            else:\n",
    "                print('*Program ready*')\n",
    "        self.search_result = []\n",
    "\n",
    "    def get_file_content(self, filePath):\n",
    "        with open(filePath, 'rb') as fp:\n",
    "            return fp.read()\n",
    "\n",
    "    def get_info(self, *args):\n",
    "        if args:\n",
    "            image = self.get_file_content(args[0])\n",
    "            self.result = self.client.general(image, self.options)\n",
    "        else:\n",
    "            img_path = get_screenshot()\n",
    "            image = self.get_file_content(img_path)\n",
    "            self.result = self.client.general(image, self.options)\n",
    "\n",
    "        answer_left = self.result['words_result'][-2]['words']\n",
    "        answer_right = self.result['words_result'][-1]['words']\n",
    "        num_and_question = ''.join([i['words']\n",
    "                                    for i in self.result['words_result'][:-2]])\n",
    "\n",
    "        punctuations = string.punctuation+punctuation\n",
    "        num_and_question = re.sub(\n",
    "            \"[{}]+\".format(punctuations), \" \", num_and_question).strip()\n",
    "        pattern = r'[0-9]{1,2}'\n",
    "        res = re.match(pattern, num_and_question, flags=0)\n",
    "        if res != None:\n",
    "            num = res.group()\n",
    "            question = num_and_question[len(str(num)):]\n",
    "        else:\n",
    "            question = num_and_question\n",
    "\n",
    "        self.info = {}\n",
    "        self.info['question'] = question\n",
    "        self.info['answer_left'] = answer_left\n",
    "        self.info['answer_right'] = answer_right\n",
    "\n",
    "        # factoid or yesorno\n",
    "        if '错' in answer_left+answer_right or '不对' in answer_left+answer_right or '正确' in answer_left+answer_right:\n",
    "            self.info['type'] = 'yesno'\n",
    "        else:\n",
    "            self.info['type'] = 'factoid'\n",
    "        return self.info\n",
    "\n",
    "    def get_answer_by_wordcount(self, qa_info, site='toutiao'):\n",
    "\n",
    "        if self.config.USE_PROXY:\n",
    "            try:\n",
    "                self.ip_pool = self.get_ips()\n",
    "            except Exception as e:\n",
    "                print(traceback.format_exc())\n",
    "            else:\n",
    "                print('*Proxy Ready*')\n",
    "\n",
    "        question = qa_info['question']\n",
    "        option_left = qa_info['answer_left']\n",
    "        option_right = qa_info['answer_right']\n",
    "        headers = {'User-Agent': get_header()}\n",
    "\n",
    "        if site == 'zhidao':\n",
    "            url = \"https://zhidao.baidu.com/search?lm=0&rn=20&pn=0&fr=search&ie=gbk&word=\" + \\\n",
    "                urllib.parse.quote(question, encoding='gbk')\n",
    "        elif site == 'wenwen':\n",
    "            url = \"http://wenwen.sogou.com/s/?w=\" + \\\n",
    "                urllib.parse.quote(question)+\"&ch=ww.header.ssda\"\n",
    "        elif site == 'sogou':\n",
    "            url = 'https://www.sogou.comsearch_resultssearch/?q=' + urllib.parse.quote(question)         \n",
    "        elif site == 'toutiao':\n",
    "            url = 'https://m.toutiao.com/search/?keyword={}&pd=synthesis&source=input&traffic_source=&original_source=&in_tfs=&in_ogs='.format(\n",
    "                question)\n",
    "        else:\n",
    "            # url = 'https://www.baidu.com/s?wd=' + question + '&pn=0'\n",
    "            print('SiteNotSupported')\n",
    "            print('Use Default site: toutiao.com')\n",
    "            url = 'https://m.toutiao.com/search/?keyword={}&pd=synthesis&source=input&traffic_source=&original_source=&in_tfs=&in_ogs='.format(\n",
    "                question)\n",
    "\n",
    "        try:\n",
    "            if self.config.USE_PROXY:\n",
    "                # 构造代理字典\n",
    "                proxies = {\n",
    "                    'http': 'http://{}'.format(self.ip_pool[random.randint(0, len(self.ip_pool)-1)])\n",
    "                }\n",
    "                response = requests.get(\n",
    "                    url=url, proxies=proxies, headers=headers, timeout=2)\n",
    "            else:\n",
    "                response = requests.get(url=url, headers=headers, timeout=2)\n",
    "\n",
    "        except requests.exceptions.ConnectTimeout as e:\n",
    "            print('TimeoutError')\n",
    "            self.get_answer_by_browser(qa_info)\n",
    "\n",
    "        if site == 'zhidao':\n",
    "            page = response.content.decode(\n",
    "                'gbk').encode('utf-8').decode('utf-8')\n",
    "            soup = bs(page, 'lxml')\n",
    "            abstracts = soup.find_all(class_=['dd answer', 'ti'])\n",
    "\n",
    "        elif site == '360':\n",
    "            page = response.content.decode('utf-8')\n",
    "            soup = bs(page, 'lxml')\n",
    "            abstracts = soup.find_all('div', class_=['qa-i-hd', 'qa-i-bd'])\n",
    "\n",
    "        elif site == 'toutiao':\n",
    "            page = response.content.decode('utf-8')\n",
    "            soup = bs(page, 'lxml')\n",
    "            abstracts = soup.find_all('div', class_=[\n",
    "                                      'ttfe-flex-item span8 ts-grid', 'ttfe-flex ttfe-flex-dir-column ttfe-article-main'])\n",
    "\n",
    "        elif site == 'wenwen':\n",
    "            page = response.content.decode('utf-8')\n",
    "            soup = bs(page, 'lxml')\n",
    "            abstracts = soup.find_all(class_=['vrTitle', 'str-text-info'])\n",
    "\n",
    "        elif site == 'sogou':\n",
    "            page = response.content.decode('utf-8')\n",
    "            soup = bs(page, 'lxml')\n",
    "            abstracts = soup.find_all(\n",
    "                'div', class_=['text-layout', 'ft', 'str-text-info', 'str_info_div'])\n",
    "        # CAUTION: prone to being blocked by baidu vertification\n",
    "        # elif site == 'baidu':\n",
    "        #     response.raise_for_status()\n",
    "        #     response.encoding = response.apparent_encoding\n",
    "        #     html = response.text\n",
    "        #     soup = bs(html, 'html.parser')\n",
    "        #     abstracts = soup.find_all('div', class_=['c-abstract','c-span18 c-span-last'])\n",
    "\n",
    "        num_left = 0\n",
    "        num_right = 0\n",
    "        candidates = ' '.join([abstra.text for abstra in abstracts])\n",
    "        if self.config.BIGRAM:\n",
    "            bigrm_left = list(map(''.join, nltk.bigrams(option_left)))\n",
    "            bigrm_right = list(map(''.join, nltk.bigrams(option_right)))\n",
    "            for bigram in bigrm_left:\n",
    "                num_left += candidates.count(bigram)\n",
    "            for bigram in bigrm_right:\n",
    "                num_right += candidates.count(bigram)\n",
    "        else:\n",
    "            num_left += candidates.count(option_left)\n",
    "            num_right += candidates.count(option_right)\n",
    "\n",
    "        if num_left == num_right:\n",
    "            print(\"高低计数相等此方法失效！\")\n",
    "            self.get_answer_by_browser(qa_info)\n",
    "        elif num_left > num_right:\n",
    "            if '不是' in question or '不属于' in question or ('未' in question and '未来' not in question):\n",
    "                print('**请注意此题为否定题,选计数最少的**')\n",
    "                return option_right\n",
    "            else:\n",
    "                return option_left\n",
    "        else:\n",
    "            if '不是' in question or '不属于' in question or ('未' in question and '未来' not in question):\n",
    "                print('**请注意此题为否定题,选计数最少的**')\n",
    "                return option_left\n",
    "            else:\n",
    "                return option_right\n",
    "\n",
    "    def get_answer_by_pagecount(self, qa_info):\n",
    "        try:\n",
    "            self.ip_pool = self.get_ips()\n",
    "        except Exception as e:\n",
    "            print(traceback.format_exc())\n",
    "        else:\n",
    "            print('*Proxy Ready*')\n",
    "\n",
    "        question = qa_info['question']\n",
    "        option_left = qa_info['answer_left']\n",
    "        option_right = qa_info['answer_right']\n",
    "\n",
    "        cnts = []\n",
    "        headers = {'User-Agent': get_header()}\n",
    "        pattern = r'[0-9,]{1,}'\n",
    "\n",
    "        keywords = ['{} {}'.format(question, option_left), '{} {}'.format(\n",
    "            question, option_right)]\n",
    "\n",
    "        for wd in keywords:\n",
    "            url = 'https://www.sogou.com/web?query={}&_asf=www.sogou.com&ie=utf8&from=index-nologin&s_from=index'.format(\n",
    "                urllib.parse.quote(wd))\n",
    "            response = requests.get(url, headers=headers, timeout=2)\n",
    "            page = response.content.decode('utf-8')\n",
    "            soup = bs(page, 'lxml')\n",
    "            s = soup.find('p', class_='num-tips').get_text()\n",
    "            page_cnt = re.search(pattern, s).group().replace(',', '')\n",
    "            cnts.append(page_cnt)\n",
    "\n",
    "        cnts = list(map(int, cnts))\n",
    "\n",
    "        num_left = cnts[0]\n",
    "        num_right = cnts[1]\n",
    "\n",
    "        if num_left == num_right:\n",
    "            print(\"高低计数相等此方法失效！\")\n",
    "            self.get_answer_by_browser(qa_info)\n",
    "        elif num_left > num_right:\n",
    "            if '不是' in question or '不属于' in question or ('未' in question and '未来' not in question):\n",
    "                print('**请注意此题为否定题,选计数最少的**')\n",
    "                return option_left\n",
    "        else:\n",
    "            if '不是' in question or '不属于' in question or ('未' in question and '未来' not in question):\n",
    "                print('**请注意此题为否定题,选计数最少的**')\n",
    "                return option_left\n",
    "            else:\n",
    "                return option_right\n",
    "\n",
    "    def get_answer_by_browser(self, qa_info):\n",
    "        webbrowser.open(\n",
    "            'https://www.baidu.com/s?ie=utf-8&f=8&rsv_bp=1&tn=baidu&wd={}&rqlang=cn&rsv_enter=1&rsv_dl=tb&rsv_sug3=41&rsv_sug2=0&rn=20'.format(qa_info['question']))\n",
    "\n",
    "    def get_ips(self):\n",
    "\n",
    "        if not self.config.IP_POOL:\n",
    "            targetUrl = Config.IP_PROXY_API\n",
    "            resp = requests.get(targetUrl)\n",
    "            ip_pool = json.loads(resp.text)['msg']\n",
    "            ip_pool = ['{0}:{1}'.format(i['ip'], i['port']) for i in ip_pool]\n",
    "            return ip_pool\n",
    "        else:\n",
    "            return self.config.IP_POOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.display()\n",
    "qa = QA(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: 动画  Lovelive 中 东条希的头发是什么颜色\t(factoid)\n",
      "*Proxy Ready*\n",
      "紫色\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "qa_info = qa.get_info()\n",
    "# qa_info = qa.get_info('img/screenshot_1576144846.png')\n",
    "print('query: {0}\\t({1})'.format(qa_info['question'], qa_info['type']))\n",
    "if qa_info['type'] == 'yesno' or config.METHOD == 'browser':\n",
    "    qa.get_answer_by_browser(qa_info)\n",
    "else:\n",
    "    if config.METHOD == 'pagecount':  # factoid only\n",
    "        print(qa.get_answer_by_pagecount(qa_info))\n",
    "    elif config.METHOD == 'wordcount':  # factoid only\n",
    "        print(qa.get_answer_by_wordcount(qa_info, site=config.SITE))\n",
    "    else:\n",
    "        print('Method not existed')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
